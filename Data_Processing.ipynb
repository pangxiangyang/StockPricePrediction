{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Processing.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1lzrFK2s5Oj3GPwZyaBtO-nuNRlcI2Jhj",
      "authorship_tag": "ABX9TyNVQBA1dLnipS0MtuadHaVt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pangxiangyang/StockPricePrediction/blob/master/Data_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6yerwmjgoHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for dir_name in dirlist:\n",
        "  \n",
        "  os.chdir(dir_name) # change directory from working dir to dir with files\n",
        "  unzipped_dir = dir_name + \"/Unzipped/\" \n",
        "  print( unzipped_dir)\n",
        "  \n",
        "  if( not os.path.isdir( unzipped_dir ) ):\n",
        "    os.makedirs( unzipped_dir)\n",
        "\n",
        "  for item in os.listdir(dir_name): # loop through items in dir\n",
        "      if item.endswith(extension): # check for \".zip\" extension\n",
        "        file_name = os.path.abspath(item) # get full path of files\n",
        "        zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
        "        zip_ref.extractall(unzipped_dir) # extract file to dir\n",
        "        zip_ref.close() # close file\n",
        "        #os.remove(file_name) # delete zipped file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVe_h-DS0olr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "unzipped_dir = '/content/drive/My Drive/NewData/8877.MY/Unzipped/'  #ekovest\n",
        "#unzipped_dir = '/content/drive/My Drive/NewData/5222.MY/Unzipped/'  #fgv\n",
        "#unzipped_dir = '/content/drive/My Drive/NewData/4715.MY/Unzipped/'  #genm\n",
        "#unzipped_dir = '/content/drive/My Drive/NewData/4723.MY/Unzipped/'  #jaks\n",
        "#unzipped_dir = '/content/drive/My Drive/NewData/7113.MY/Unzipped/'  #topglove\n",
        "#unzipped_dir = '/content/drive/My Drive/NewData/6947.MY/Unzipped/'  #digi\n",
        "#unzipped_dir = '/content/drive/My Drive/NewData/8869.MY/Unzipped/' #pmetal\n",
        "#unzipped_dir = '/content/drive/My Drive/NewData/7160.MY/Unzipped/' #penta\n",
        "\n",
        "li = [];\n",
        "filePrefix = \"quotemovements_\";\n",
        "dateLength = len(\"20191106\"); \n",
        "\n",
        "# Get all the files in unzipped folder in ascending order\n",
        "print( sorted( os.listdir(unzipped_dir) )) \n",
        "for item in sorted( os.listdir(unzipped_dir) ): # loop through items in dir\n",
        "  startIndex = item.find(\"_\", len( filePrefix) )\n",
        "  date = item[startIndex+1:startIndex+dateLength+1]\n",
        "  filepath = os.path.abspath(os.path.join(unzipped_dir, item))\n",
        "  df = pd.read_csv( filepath)\n",
        "  df[\"Date\"] = date\n",
        "  df = df[::-1]   # Reverse the order of data frame\n",
        "  li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "frame.head()\n",
        "frame['Datetime'] = pd.to_datetime(frame[\"Date\"] + \" \" + frame[\"Time\"])\n",
        "frame[\"Index\"]    = range(len(frame))\n",
        "#frame.sort_values( by = ['Datetime'], inplace = True )\n",
        "frame = frame.set_index('Index')\n",
        "frame.to_csv( \"/content/test.csv\" );"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiZMniUEEAeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get data for certain day\n",
        "allDates = frame[\"Date\"].unique()\n",
        "print( len( allDates) )\n",
        "processedData = {};\n",
        "data = {};\n",
        "for date in allDates:\n",
        "  subset = frame[\"Date\"] == date\n",
        "  dailyData = frame[subset]\n",
        "  dailyData.loc[:,'Last Done Price'] = dailyData.loc[:,'Last Done Price'].ffill()\n",
        "  dailyData.fillna( 0, inplace = True )\n",
        "  dailyData.to_csv( \"/content/feff.csv\" );\n",
        "\n",
        "  # Get the unique buy & sell prices of the day\n",
        "  buyPrice = dailyData[ dailyData['Buy Price'] > 0.0 ]['Buy Price'].unique()\n",
        "  buyPriceList = {}\n",
        "  for price in buyPrice:\n",
        "    buyPriceList[price] = 0.0\n",
        "\n",
        "  sellPrice = dailyData[ dailyData['Sell Price'] > 0.0 ]['Sell Price'].unique()\n",
        "  sellPriceList = {}\n",
        "  for price in sellPrice:\n",
        "    sellPriceList[price] = 0.0\n",
        "\n",
        "  dailyData['CurrentSupply']  = 0.0\n",
        "  dailyData['CurrentDemand']  = 0.0\n",
        "  dailyData[\"TotalDemand\"]    = 0.0  \n",
        "  dailyData[\"TotalSupply\"]    = 0.0\n",
        "  dailyData[\"BuyUpTrade\"]     = 0.0\n",
        "  dailyData[\"SellDownTrade\"]  = 0.0\n",
        "  dailyData[\"PreOpenTrade\"]   = 0.0  \n",
        "  \n",
        "  buyUpTrade = 0.0;\n",
        "  sellDownTrade = 0.0;\n",
        "  preOpenTrade  = 0.0;\n",
        "\n",
        "  for index, row in dailyData.iterrows():\n",
        "      buyPrice     = row[\"Buy Price\"]\n",
        "      buyVolChg    = row[\"Buy Vol Change\"]\n",
        "      buyVol       = row[\"Buy Vol\"]\n",
        "      sellVolChg   = row[\"Sell Vol Change\"]\n",
        "      sellPrice    = row[\"Sell Price\"]\n",
        "      sellVol      = row[\"Sell Vol\"]\n",
        "      tradeVol     = row[\"Last Done Vol\"]\n",
        "      tradePrice   = row[\"Last Done Price\"]\n",
        "      tradeType    = row[\"Type\"]\n",
        "      \n",
        "      currentDemand = buyPrice * buyVol\n",
        "      currentSupply = sellPrice * sellVol\n",
        "      price = tradeVol * tradePrice;\n",
        "      if(tradeType == \"Preopen\"):\n",
        "        preOpenTrade = price + preOpenTrade\n",
        "      elif( tradeType == \"Buy Up\" ):\n",
        "        buyUpTrade = price + buyUpTrade\n",
        "      elif( tradeType == \"Sell Down\"):\n",
        "        sellDownTrade = price + sellDownTrade\n",
        "\n",
        "      # Calculate accumulated total buy / sell \n",
        "      if( row[\"Buy Price\"] in buyPriceList ):\n",
        "        buyPriceList[row[\"Buy Price\"]] = currentDemand\n",
        "      if( row[\"Sell Price\"] in sellPriceList ):\n",
        "        sellPriceList[row[\"Sell Price\"]] = currentSupply\n",
        "\n",
        "      accumulatedDemand = sum(buyPriceList.values())\n",
        "      accumulatedSupply = sum(sellPriceList.values())\n",
        "\n",
        "      dailyData.loc[index, 'CurrentSupply']    = currentSupply\n",
        "      dailyData.loc[index, 'CurrentDemand']    = currentDemand\n",
        "      dailyData.loc[index, 'TotalDemand']      = accumulatedDemand    \n",
        "      dailyData.loc[index, 'TotalSupply']      = accumulatedSupply\n",
        "      dailyData.loc[index, \"BuyUpTrade\"]       = buyUpTrade\n",
        "      dailyData.loc[index, \"SellDownTrade\"]    = sellDownTrade\n",
        "      dailyData.loc[index, \"PreOpenTrade\"]     = preOpenTrade\n",
        "      dailyData.loc[index, \"TotalTrade\"]       = buyUpTrade + sellDownTrade + preOpenTrade\n",
        "\n",
        "  dailyData2 = dailyData[['Datetime', 'TotalDemand', 'TotalSupply', 'TotalTrade', 'BuyUpTrade', 'SellDownTrade', 'PreOpenTrade', 'Last Done Price', 'Time']].copy()\n",
        "  dailyData2 = dailyData2.set_index('Datetime')\n",
        "  aggregatedData = dailyData2.resample( '5T' ).last() # get last record for every 5 minutes\n",
        "  aggregatedData.dropna(subset = [\"Time\"], inplace=True) # drop empty row  from trade break\n",
        "  data[date]   = dailyData2\n",
        "  processedData[date] = aggregatedData\n",
        "  #aggregatedData.to_csv(\"/content/\" + date +\".csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYah8NWkJKEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = {};\n",
        "import numpy as np\n",
        "from decimal import Decimal\n",
        "#Google trend\n",
        "colnames=['Date', 'Popularity'] \n",
        "\n",
        "gtfilepath = \"/content/drive/My Drive/GoogleTrend/MAYBANK.csv\"\n",
        "gtfilepath = \"/content/drive/My Drive/GoogleTrend/REVENUE.csv\"\n",
        "gtfilepath = \"/content/drive/My Drive/GoogleTrend/HIBISCS.csv\"\n",
        "gtfilepath = \"/content/drive/My Drive/GoogleTrend/AIRASIA.csv\"\n",
        "gtfilepath = \"/content/drive/My Drive/GoogleTrend/EKOVEST.csv\"\n",
        "#gtfilepath = \"/content/drive/My Drive/GoogleTrend/FGV.csv\"\n",
        "#gtfilepath = \"/content/drive/My Drive/GoogleTrend/GENM.csv\"\n",
        "#gtfilepath = \"/content/drive/My Drive/GoogleTrend/JAKS.csv\"\n",
        "#gtfilepath = \"/content/drive/My Drive/GoogleTrend/TOPGLOVE.csv\"\n",
        "#gtfilepath = \"/content/drive/My Drive/GoogleTrend/DIGI.csv\"\n",
        "#gtfilepath = \"/content/drive/My Drive/GoogleTrend/PMETAL.csv\"\n",
        "#gtfilepath = \"/content/drive/My Drive/GoogleTrend/PENTA.csv\"\n",
        "\n",
        "\n",
        "googleTrend = pd.read_csv(gtfilepath, skiprows = 3, names = colnames )\n",
        "googleTrend['Index'] = googleTrend['Date'].apply(lambda x: x.replace(\"-\",\"\") )\n",
        "\n",
        "for key,value in data.items():\n",
        "  aggregatedData = value.resample( '60T' ).last() # get last record for every 1hour\n",
        "  aggregatedData['Popularity'] = googleTrend[googleTrend['Index'] == key]['Popularity'].iloc[0]\n",
        "  aggregatedData['TotalTrade'].replace( 0.00, np.nan)\n",
        "  aggregatedData.dropna(subset = [\"TotalTrade\"], inplace=True) # drop empty row  from trade break\n",
        "  aggregatedData = aggregatedData.loc[ ~np.isclose( aggregatedData['Last Done Price'], 0.00 ) ]\n",
        "  print(aggregatedData)\n",
        "  test[key] = aggregatedData\n",
        "\n",
        "# Concatenate dataset\n",
        "hourdata = pd.concat( test, axis = 0 );\n",
        "\n",
        "# Export to csv\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/MAYBANK.csv\"\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/REVENUE.csv\"\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/HIBISCS.csv\"\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/AIRASIA.csv\"\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/EKOVEST.csv\"\n",
        "##finalfilepath = \"/content/drive/My Drive/FinalizedData/FGV.csv\"\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/GENM.csv\"\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/JAKS.csv\"\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/TOPGLOVE.csv\"\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/DIGI.csv\"\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/PMETAL.csv\"\n",
        "#finalfilepath = \"/content/drive/My Drive/FinalizedData/PENTA.csv\"\n",
        "\n",
        "hourdata.to_csv(finalfilepath)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}